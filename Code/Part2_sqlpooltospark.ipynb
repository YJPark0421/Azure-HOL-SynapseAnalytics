{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "%%spark\r\n",
        "val df = spark.read.sqlanalytics(\"aaasqlpool.dbo.dataflow_table\") \r\n",
        "df.write.mode(\"overwrite\").saveAsTable(\"default.dataflowsparkwowdataset\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "df: org.apache.spark.sql.DataFrame = [identifierid: string, level: int ... 19 more fields]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ]
}